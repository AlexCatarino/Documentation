<p>
 The following examples demonstrate some common practices for using
 <code>
  XGBoost
 </code>
 library.
</p>
<h4>
 Example 1: Gradient Boosting Model
</h4>
<p>
 The below algorithm makes use of
 <code>
  XGBoost
 </code>
 library to predict the future price movement using the previous 5 OHLCV data. The model is trained using rolling 2-year data. To ensure the model applicable to the current market environment, we recalibrate the model on every Sunday.
</p>
<div class="section-example-container testable">
 <pre class="python">import xgboost as xgb
import joblib

class XGBoostExampleAlgorithm(QCAlgorithm):
  
    def initialize(self) -&gt; None:
        self.set_start_date(2024, 9, 1)
        self.set_end_date(2024, 12, 31)
        self.set_cash(100000)
        # Request SPY data for model training, prediction and trading.
        self.symbol = self.add_equity("SPY", Resolution.DAILY).symbol

        # 2-year data to train the model.
        training_length = 252*2
        self.training_data = RollingWindow(training_length)
        # Warm up the training dataset to train the model immediately.
        history = self.history[TradeBar](self.symbol, training_length, Resolution.DAILY)
        for trade_bar in history:
            self.training_data.add(trade_bar.close)

        # Retrieve already trained model from object store to use immediately.
        self._model_key = "xgboost-example-model"
        if self.live_mode and self.object_store.contains_key(self._model_key):
            file_name = self.object_store.get_file_path(self._model_key)
            self.model = joblib.load(file_name)
        else:
            # Train the model to use the prediction right away.
            self.train(self.my_training_method)
            
        # Recalibrate the model weekly to ensure its accuracy on the updated domain.
        self.train(self.date_rules.every(DayOfWeek.SUNDAY), self.time_rules.at(8,0), self.my_training_method)
        
    def get_features_and_labels(self, n_steps=5) -&gt; None:
        # Train and predict the partial-differencing data, which is more stationary while more variance remaining.
        close_prices = np.array(list(self.training_data)[::-1])
        df = (np.roll(close_prices, -1) - close_prices) * 0.5 + close_prices * 0.5
        df = df[:-1]

        # Stack the data for 5-day OHLCV data per each sample to train with.
        features = []
        labels = []
        for i in range(len(df)-n_steps):
            features.append(df[i:i+n_steps])
            labels.append(df[i+n_steps])

        features = np.array(features)
        labels = np.array(labels)
        features = (features - features.mean()) / features.std()
        labels = (labels - labels.mean()) / labels.std()

        d_matrix = xgb.DMatrix(features, label=labels)

        return d_matrix

    def my_training_method(self) -&gt; None:
        # Prepare the processed training data.
        d_matrix = self.get_features_and_labels()
        # Recalibrate the model based on updated data.
        params = {
            'booster': 'gbtree',
            'colsample_bynode': 0.8,
            'learning_rate': 0.1,
            'lambda': 0.1,
            'max_depth': 5,
            'num_parallel_tree': 100,
            'objective': 'reg:squarederror',
            'subsample': 0.8,
        }
        self.model = xgb.train(params, d_matrix, num_boost_round=2)

    def on_data(self, slice: Slice) -&gt; None:
        if self.symbol in slice.bars:
            self.training_data.add(slice.bars[self.symbol].close)

        # Get prediction by the updated features.
        new_d_matrix = self.get_features_and_labels()
        prediction = self.model.predict(new_d_matrix)
        prediction = prediction.flatten()

        # If the predicted direction is going upward, buy SPY.
        if float(prediction[-1]) &gt; float(prediction[-2]):
            self.set_holdings(self.symbol, 1)
        # If the predicted direction is going downward, sell SPY.
        else:            
            self.set_holdings(self.symbol, -1)

    def on_end_of_algorithm(self) -&gt; None:
        # Store the model to object store to retrieve it in other instances in case the algorithm stops.
        if not self.live_mode:
            return
        file_name = self.object_store.get_file_path(self._model_key)
        joblib.dump(self.model, file_name)
        self.object_store.save(self._model_key)</pre>
 <script class="python-result" type="text">
  {
    "Total Orders": "1",
    "Average Win": "0%",
    "Average Loss": "0%",
    "Compounding Annual Return": "279.779%",
    "Drawdown": "0.100%",
    "Expectancy": "0",
    "Start Equity": "100000",
    "End Equity": "101720.74",
    "Net Profit": "1.721%",
    "Sharpe Ratio": "16.657",
    "Sortino Ratio": "0",
    "Probabilistic Sharpe Ratio": "98.933%",
    "Loss Rate": "0%",
    "Win Rate": "0%",
    "Profit-Loss Ratio": "0",
    "Alpha": "-0.536",
    "Beta": "1.038",
    "Annual Standard Deviation": "0.116",
    "Annual Variance": "0.013",
    "Information Ratio": "-31.283",
    "Tracking Error": "0.014",
    "Treynor Ratio": "1.855",
    "Total Fees": "$1.37",
    "Estimated Strategy Capacity": "$1200000000.00",
    "Lowest Capacity Asset": "SPY R735QTJ8XC9X",
    "Portfolio Turnover": "19.88%",
    "Drawdown Recovery": "0",
    "OrderListHash": "c661b5fb5f1cc7f1e24b1c8e20bb05f7"
}
 </script>
</div>
