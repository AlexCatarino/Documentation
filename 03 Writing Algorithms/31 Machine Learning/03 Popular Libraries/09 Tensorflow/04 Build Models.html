<p>In this example, build a neural-network regression prediction model that uses the following features and labels:</p>

<table class="qc-table table">
    <thead>
        <tr>
            <th>Data Category</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Features</td>
            <td>The last 5 close price differencing compared to current price</td>
        </tr>
        <tr>
            <td>Labels</td>
            <td>The following day's price change</td>
        </tr>
    </tbody>
</table>

<p>The following image shows the time difference between the features and labels:</p>
<img class="docs-image" alt="Features and labels for training" src="https://cdn.quantconnect.com/i/tu/ml-tf.png">

<p>Follow these steps to create a method to build the model:</p>
<ol>
    <li>Define some parameters, including the number of factors, neurons, and epochs.</li>
    <div class="section-example-container">
        <pre class="python"># Set some hyperparameters:
num_factors = 5     # Set the number of input features.
num_neurons_1 = 10  # Set the neurons in each hidden layer to capture complexity.
num_neurons_2 = 10
num_neurons_3 = 5
self.epochs = 20    # Set the training epochs for sufficient learning.
self.learning_rate = 0.0001  # Set the learning rate for optimization control.</pre>
    </div>
    
    <li>Create the model using built-in Keras API.</li>
    <div class="section-example-container">
        <pre class="python"># Define the model with sequential layers: an input layer with ReLU activation to introduce non-linearity, 
# two hidden layers for feature extraction, and an output layer for predictions.
self.model = tf.keras.sequential([
    tf.keras.layers.dense(num_neurons_1, activation=tf.nn.relu, input_shape=(num_factors,)),  # The input shape is required.
    tf.keras.layers.dense(num_neurons_2, activation=tf.nn.relu),
    tf.keras.layers.dense(num_neurons_3, activation=tf.nn.relu),
    tf.keras.layers.dense(1)
])</pre>
    </div>
</ol>
