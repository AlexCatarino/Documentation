<p>Follow these steps to load the pre-trained FinBERT model:</p>

<ol>
  <li>Import the model and tokenizer classes.</li>
  <div class="section-example-container">
    <pre class="python">from transformers import TFBertForSequenceClassification, BertTokenizer</pre> 
  </div>

  <li>Define the path were the model is stored.</li>
  <p>In QuantConnect Cloud, the path is <span class='public-file-name'>ProsusAI / finbert</span>.</p>
  <div class="section-example-container">
    <pre class="python">model_path = "ProsusAI/finbert"</pre> 
  </div>

  <li>Create a <a rel='nofollow' target='_blank' href='https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification'>TFBertForSequenceClassification</a> model.</li>
  <div class="section-example-container">
    <pre class="python">self._model = TFBertForSequenceClassification.from_pretrained(model_path, local_files_only=True)</pre> 
  </div>

  <li>Create a <a rel='nofollow' target='_blank' href='https://huggingface.co/docs/transformers/en/model_doc/bert#transformers.BertTokenizer'>BertTokenizer</a> object.</li>
  <div class="section-example-container">
    <pre class="python">self._tokenizer = BertTokenizer.from_pretrained(model_path, local_files_only=True)</pre> 
  </div>

  <li><span class='qualifier'>(Optional)</span> Set the seed to enable reproducibility.</li>
  <div class="section-example-container">
    <pre class="python">from transformers import set_seed
set_seed(1, True)</pre> 
  </div>
</ol>

<p>Follow these steps to analyze the sentiment of some text:</p>
<ol>
  <li>Get the text you want the model to analyze.</li>
  <p>The model can analyze a single sentence or a list of sentences.</p>
  <div class="section-example-container">
    <pre class="python">content = "AAPL stock price spikes after record-breaking sales figures."</pre> 
  </div>

  <li>Tokenize the text(s).</li>
  <div class="section-example-container">
    <pre class="python">inputs = self._tokenizer(content, padding=True, truncation=True, return_tensors='tf')</pre> 
  </div>
  <p>For more information about how to tokenize, see the <a rel='nofollow' target='_blank' href='https://huggingface.co/docs/transformers/main/en/main_classes/tokenizer#transformers.PreTrainedTokenizer.__call__'>PreTrainedTokenizer.__call__</a> reference on the Hugging Face website.</p>

  <li>Perform dictionary unpacking on the preceding result and pass it to the model as input.</li>
  <div class="section-example-container">
    <pre class="python">outputs = self._model(**inputs)</pre> 
  </div>

  <li>Apply softmax to the outputs to get probabilities of the text sentiment.</li>
  <div class="section-example-container">
    <pre class="python">scores = tf.nn.softmax(outputs.logits, axis=-1).numpy()</pre> 
  </div>

  <p>
    The result of the preceding operation is a two dimensional numpy array. 
    Each element in the two dimensional array is a list that contains the probability that the sentiment of the corresponding sentence is negative, neutral, or postiive, respectively.
    For example, you may get the following result if you use a single sentence as input.
    The result shows that the input is more positive than negative, but is likely neutral.
  </p>
  <div class="section-example-container">
    <pre class="python">array([[0.21346861, 0.46771246, 0.318819]])</pre> 
  </div>
</ol>
