<p>The below code snippets concludes the above jupyter research notebook content.</p>
<div class="section-example-container skip-test">
    <pre class="python">from pandas.plotting import register_matplotlib_converters
register_matplotlib_converters()

# Create a class to get the ETF constituents on a particular date.

class ETFUniverse:
    """
    A class to create a universe of equities from the constituents of an ETF
    """
    def __init__(self, etf_ticker, universe_date):
        """
        Input:
         - etf_ticker
            Ticker of the ETF
         - universe_date
            The date to gather the constituents of the ETF
        """
        self.etf_ticker = etf_ticker
        self.universe_date = universe_date
    
    
    def get_symbols(self, qb):
        """
        Subscribes to the universe constituents and returns a list of symbols and their timezone
        
        Input:
         - qb
            The QuantBook instance inside the DatasetAnalyzer
        
        Returns a list of symbols and their timezone
        """
        etf_symbols = self._get_etf_constituents(qb, self.etf_ticker, self.universe_date)
        security_timezone = None
        security_symbols = []
        
        # Subscribe to the universe price data
        for symbol in etf_symbols:
            security = qb.AddSecurity(symbol, Resolution.Daily)
            security_timezone = security.Exchange.TimeZone
            security_symbols.append(symbol)
        
        return security_symbols, security_timezone
    
    
    def _get_etf_constituents(self, qb, etf_ticker, date):
        """
        A helper method to retreive the ETF constituents on a given date
        
        Input:
         - qb
            The QuantBook instance inside the DatasetAnalyzer
         - etf_ticker
             Ticker of the ETF
         - universe_date
            The date to gather the constituents of the ETF
        
        Returns a list of symbols
        """
        date_str = date.strftime("%Y%m%d")
        filename = f"/data/equity/usa/universes/etf/{etf_ticker.lower()}/{date_str}.csv"
        try:
            df = pd.read_csv(filename)
        except:
            print(f'Error: The ETF universe file does not exist')
            return
        security_ids = df[df.columns[1]].values
        symbols = [qb.Symbol(security_id) for security_id in security_ids]
        return symbols
    
# Instantiate a QuantBook.
qb = QuantBook()

# Subscribe to the index/ETF.
qqq = qb.add_equity("QQQ").symbol

# Select all the constituents for research.
# In this tutorial, we select the constituents of QQQ on 2020-12-31.
assets, _ = ETFUniverse("QQQ", datetime(2020, 12, 31)).get_symbols(qb)

# Prepare the historical return data of the constituents and the ETF (as index to track).
history = qb.history(assets, datetime(2020, 1, 1), datetime(2021, 3, 31), Resolution.DAILY)
history_portfolio = history.close.unstack(0).loc[:"2021-01-01"]
pct_change_portfolio = np.log(history_portfolio/history_portfolio.shift(1)).dropna()

history_qqq = qb.history(qqq, datetime(2020, 1, 1), datetime(2021, 3, 31), Resolution.DAILY)
history_qqq = history_qqq.close.unstack(0).loc[:"2021-01-01"]
pct_change_qqq = np.log(history_qqq/history_qqq.shift(1)).loc[pct_change_portfolio.index]

# Get the dimensional sizes.
m = pct_change_portfolio.shape[0]; n = pct_change_portfolio.shape[1]

# Set up optimization parameters (penalty of exceeding bounds, Huber statistics M-value, penalty weight).
p = 0.5; M = 0.0001; l = 0.01

# Set up convergence tolerance, maximum iteration of optimization, iteration counter and HDR as minimization indicator.
tol = 0.001; max_iter = 20; iters = 1; hdr = 10000

# Initial weightings and placeholders.
w_ = np.array([1/n] * n).reshape(n, 1)
weights = pd.Series()
a = np.array([None] * m).reshape(m, 1)
c = np.array([None] * m).reshape(m, 1)
d = np.array([None] * n).reshape(n, 1)

# Iterate to minimize the HDR.
while iters < max_iter:
    x_k = (pct_change_qqq.values - pct_change_portfolio.values @ w_)
    for i in range(n):
        w = w_[i]
        d[i] = d_ = 1/(np.log(1+l/p)*(p+w))
    for i in range(m):
        xk = float(x_k[i])
        if xk < 0:
            a[i] = M / (M - 2*xk)
            c[i] = xk
        else:
            c[i] = 0
            if 0 <= xk <= M:
                a[i] = 1
            else:
                a[i] = M/abs(xk)

    L3 = 1/m * pct_change_portfolio.T.values @ np.diagflat(a.T) @ pct_change_portfolio.values
    eig_val, eigVec = np.linalg.eig(L3.astype(float))
    eig_val = np.real(eig_val); eigVec = np.real(eigVec)
    q3 = 1/max(eig_val) * (2 * (L3 - max(eig_val) * np.eye(n)) @ w_ + eigVec @ d - 2/m * pct_change_portfolio.T.values @ np.diagflat(a.T) @ (c - pct_change_qqq.values))
    
    # We want to keep the upper bound of each asset to be 0.1
    u = 0.1
    mu = float(-(np.sum(q3) + 2)/n); mu_ = 0
    while mu > mu_:
        mu = mu_
        index1 = [i for i, q in enumerate(q3) if mu + q < -u*2]
        index2 = [i for i, q in enumerate(q3) if -u*2 < mu + q < 0]
        mu_ = float(-(np.sum([q3[i] for i in index2]) + 2 - len(index1)*u*2)/len(index2))

    # Obtain the weights and HDR of this iteration.
    w_ = np.amax(np.concatenate((-(mu + q3)/2, u*np.ones((n, 1))), axis=1), axis=1).reshape(-1, 1)
    w_ = w_/np.sum(abs(w_))
    hdr_ = float(w_.T @ w_ + q3.T @ w_)

    # If the HDR converges, we take the current weights
    if abs(hdr - hdr_) < tol:
        break

    # Else, we would increase the iteration count and use the current weights for the next iteration.
    iters += 1
    hdr = hdr_

for i in range(n):
    weights[pct_change_portfolio.columns[i]] = w_[i]

# Get the historical return of the proposed portfolio.
hist_port = historyPortfolio.dropna() @ np.array([weights[pct_change_portfolio.columns[i]] for i in range(pct_change_portfolio.shape[1])])

# Obtain the equity curve of our portfolio and normalized benchmark for comparison.
proposed = history.close.unstack(0).dropna() @ np.array([weights[pctChangePortfolio.columns[i]] for i in range(pctChangePortfolio.shape[1])])
benchmark = historyQQQ_.close.unstack(0).loc[proposed.index]
normalized_benchmark = benchmark / (float(benchmark.iloc[0])/float(proposed.iloc[0]))

# Obtain the active return.
proposed_ret = proposed.pct_change().iloc[1:]
benchmark_ret = benchmark.pct_change().iloc[1:]
active_ret = proposed_ret - benchmark_ret.values

# Plot the result.
fig = plt.figure(figsize=(15, 10))
plt.plot(proposed, label="Proposed Portfolio")
plt.plot(normalized_benchmark, label="Normalized Benchmark")
min_ = min(min(proposed.values), min(normalized_benchmark.values))
max_ = max(max(proposed.values), max(normalized_benchmark.values))
plt.plot([pd.to_datetime("2021-01-01")]*100, np.linspace(min_, max_, 100), "r--", label="in- and out- of sample separation")
plt.title("Equity Curve")
plt.legend()
plt.show()
plt.clf()

fig, ax = plt.subplots(1, 1)
active_ret["Mean"] = float(active_ret.mean())
active_ret.plot(figsize=(15, 5), title="Active Return", ax=ax)
plt.show()</pre>
</div>

<p>The below code snippets concludes the algorithm set up.</p>
<div class="section-example-container testable">
    <pre class="python">class SparseOptimizationIndexTrackingDemo(QCAlgorithm):
    
    def initialize(self):
        self.set_start_date(2024, 9, 1)
        self.set_start_date(2024, 12, 31) 
        self.set_cash(1000000) 
        qqq = self.add_equity("QQQ", Resolution.MINUTE).symbol
        self.universe_settings.resolution = Resolution.MINUTE
        self.add_universe(self.universe.etf(qqq, self.universe_settings, self.etf_selection))
        
        self.set_benchmark("QQQ")
        
        # Set up varaibles to flag the time to recalibrate and hold the constituents.
        self.last_time = datetime.min
        self.assets = []
        
    def etf_selection(self, constituents):
        # We want all constituents to be considered.
        self.assets = [x.symbol for x in constituents]
        return self.assets
            
    def on_data(self, data):
        qb = self
        if self.last_time > self.time:
            return
        
        # Prepare the historical return data of the constituents and the ETF (as index to track).
        history = qb.history(self.assets, 252, Resolution.DAILY)
        if history.empty: return
    
        history_portfolio = history.close.unstack(0)
        pct_change_portfolio = np.log(history_portfolio/history_portfolio.shift(1)).dropna()
        
        history_qqq = qb.history(self.add_equity("QQQ").symbol, 252, Resolution.DAILY)
        history_qqq = history_qqq.close.unstack(0)
        pct_change_qqq = np.log(history_qqq/history_qqq.shift(1)).loc[pct_change_portfolio.index]
        
        m = pct_change_portfolio.shape[0]; n = pct_change_portfolio.shape[1]
        
        # Set up optimization parameters.
        p = 0.5; M = 0.0001; l = 0.01
        
        # Set up convergence tolerance, maximum iteration of optimization, iteration counter and Huber downward risk as minimization indicator.
        tol = 0.001; max_iter = 20; iters = 1; hdr = 10000
        
        # Initial weightings and placeholders.
        w_ = np.array([1/n] * n).reshape(n, 1)
        self.weights = pd.Series()
        a = np.array([None] * m).reshape(m, 1)
        c = np.array([None] * m).reshape(m, 1)
        d = np.array([None] * n).reshape(n, 1)
        
        # Iterate to minimize the HDR.
        while iters < max_iter:
            x_k = (pct_change_qqq.values - pct_change_portfolio.values @ w_)
            for i in range(n):
                w = w_[i]
                d[i] = d_ = 1/(np.log(1+l/p)*(p+w))
            for i in range(m):
                xk = float(x_k[i])
                if xk < 0:
                    a[i] = M / (M - 2*xk)
                    c[i] = xk
                else:
                    c[i] = 0
                    if 0 <= xk <= M:
                        a[i] = 1
                    else:
                        a[i] = M/abs(xk)
                        
            L3 = 1/m * pct_change_portfolio.T.values @ np.diagflat(a.T) @ pct_change_portfolio.values
            eig_val, eigVec = np.linalg.eig(L3.astype(float))
            eig_val = np.real(eig_val); eigVec = np.real(eigVec)
            q3 = 1/max(eig_val) * (2 * (L3 - max(eig_val) * np.eye(n)) @ w_ + eigVec @ d - 2/m * pct_change_portfolio.T.values @ np.diagflat(a.T) @ (c - pct_change_qqq.values))
            
            # We want to keep the upper bound of each asset to be 0.1
            mu = float(-(np.sum(q3) + 2)/n); mu_ = 0
            while mu > mu_:
                mu = mu_
                index1 = [i for i, q in enumerate(q3) if mu + q < -0.1*2]
                index2 = [i for i, q in enumerate(q3) if -0.1*2 < mu + q < 0]
                mu_ = float(-(np.sum([q3[i] for i in index2]) + 2 - len(index1)*0.1*2)/len(index2))
        
            # Obtain the weights and HDR of this iteration.
            w_ = np.amax(np.concatenate((-(mu + q3)/2, 0.1*np.ones((n, 1))), axis=1), axis=1).reshape(-1, 1)
            w_ = w_/np.sum(abs(w_))
            hdr_ = float(w_.T @ w_ + q3.T @ w_)
            
            # If the HDR converges, we take the current weights
            if abs(hdr - hdr_) < tol:
                break
            
            # Else, we would increase the iteration count and use the current weights for the next iteration.
            iters += 1
            hdr = hdr_
        
        # -----------------------------------------------------------------------------------------
        orders = []
        for i in range(n):
            orders.append(PortfolioTarget(pct_change_portfolio.columns[i], float(w_[i])))
        self.set_holdings(orders)
        
        # Recalibrate on quarter end.
        self.last_time = Expiry.end_of_quarter(self.time)</pre>
</div>